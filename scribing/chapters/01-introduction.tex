\chapter{Introduction to Optimization}

\section{Hashed Array Tree}

\begin{tcolorbox}[title=Terminology]
	To avoid confusion, we will use the following definitions for \textit{size} and \textit{capacity}:
	\begin{itemize}
		\item \textbf{Size} refers to the number of elements in a data structure (often denoted as $n$ or $N$)
		\item \textbf{Capacity} refers to the maximum number of elements a data structre can hold
	\end{itemize}
\end{tcolorbox}

\subsection*{Structure}

\begingroup

\begin{wrapfigure}{l}{0.4\textwidth}
	\centering
	\includegraphics[width=0.4\textwidth]{01/structure.png}
    \caption{HAT with $B=4$}\label{hashed-tree-diagram}
\end{wrapfigure}
Despite the name, hashed array trees (HAT) have nothing to do with hashing or trees. Instead, it is more
akin to a 2D array$-$a 2-level structure where the first level (\textit{Top}) keeps track of the 
second level (\textit{Leaf/Leaves}). The the capacity of the Top array and each Leaf are dictated
by $B$, an integer $\geq1$. For the sake of simplicity, we will also assume that $B$ is always
a power of two.

Since both Top and Leaf each has a capacity of $B$, the entire HAT has a capacity of $B^2$.
Let $n$ be the size of the entire HAT.
\begin{equation}\label{hat-invariant}
	\left(\frac{B}{4}\right)^2 \leq n \leq B^2
\end{equation}
The proof for this will come later on in the notes when we look at expanding and shrinking HATs.

\endgroup

\subsection*{Resizing}

\begingroup

When a HAT is full, its policy for growing is by doubling $B$ and copying data over. This achieves
a couple things. It ensures that $B$ is still a power of 2. It also quadruples the capacity of the
HAT. Suppose that the current capacity of the HAT is $N$, the new capacity will be
\[(2B)^2 = 4B^2 = 4N \]

Conversely, $B$ is halved when a HAT becomes too sparse. Here, we define a sparse HAT to be a HAT 
where the number of elements $N \leq (B/4)^2$. Suppose that the current capacity of the HAT is $N$,
the new capacity will become 

\endgroup

\subsection*{Accessing an Element}

\begingroup

Suppose we are trying to access element $e$ at index $i$. We need to compute an index for Top to get
the right Leaf, then compute another index for the Leaf to get $e$. The index for Top and Leaf can
be computed by $\floor{i/B}$ and $i \pmod B$ respectively.

Since division and modulo are rather expensive operations, there are ways to speed these operations
up. Recall the assumption that $B$ is always a power of 2, meaning $B = 2^k$ for some
positive integer $k$. $\floor{i/B}$ can now be simply computed by \mintinline{c}{i >> k}. 
Additionally, the same property also simplifies the modulo operation as it can be computing by
\mintinline{c}{i & (1 << k - 1)}.

\endgroup

\subsection*{Space Analysis}

\begingroup

\begin{wrapfigure}{r}{0.4\textwidth}
	\vspace*{-20pt}
	\centering
	\includegraphics[width=0.4\textwidth]{01/space.png}
	\caption{Space usage of a HAT}
	\vspace*{-20pt}
\end{wrapfigure}

Consider a HAT with size $N$ and an arbitrary $B$. We need $B$ \textit{slots} to be the Top array,
$N$ slots for the elements themselves, and at most another $B$ slots for the Leaf that is not full
yet. Therefore, the space usage of the HAT is $N + 2B$. Recall that $N = B^2$, we can also rewrite
the space usage as $N + 2\sqrt{N} = N + O(\sqrt{N})$.

\subsection*{Amortized Time Analysis for Expansion}

Consider a full HAT of size $N$ and some arbitrary $B$. For the sake of simplicity, let us assume
that the memory allocation is magically instantaneous. This means that, on average, each append
operation would be constant time since writing to an array takes constant time as well.
Thus, the growing cost comes mainly from copying the $N$ elements over from the old HAT
to the new one.

Since we only expand the HAT ever so often, we would have \textit{cheap} operations to make up for 
the expensive expansion operations. In order to find the number of cheap append operations between
expansions, we can simply compute the difference between the capacity of each expansion. Since $B$
is doubled in each expansion, we know that the $B$ before the last expasion would be half of the
current one. Therefore, we can compute the following to get the difference.
\[ B^2 - \left(\frac{B}{2}\right)^2 \]
This can then be rewritten in terms of $N$ and we will obtain.
\[ N - \frac{N}{4} = \frac{3}{4}N \]

Therefore, the amortized cost per append operation would be constant time.
\[ \frac{N}{(3/4)N} = \frac{4}{3} \in O(1) \]

\endgroup